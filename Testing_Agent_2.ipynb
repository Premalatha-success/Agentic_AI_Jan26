{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTO1LO5A32Gn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a30576d"
      },
      "source": [
        "# Task\n",
        "Predict \"Customer Lifetime Value\" using the `AutoInsurance.csv` dataset, building and evaluating Linear Regression, Random Forest Regressor, and Gradient Boosting Regressor models. Select the best performing model and deploy it with a Gradio interface."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1230d8af"
      },
      "source": [
        "## Load and Initial Data Inspection\n",
        "\n",
        "### Subtask:\n",
        "Load the 'AutoInsurance.csv' dataset and perform an initial inspection to understand its structure, identify data types, and check for missing values.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26194a47"
      },
      "source": [
        "**Reasoning**:\n",
        "To address all instructions in the subtask, I will first import the pandas library, then load the specified CSV file into a DataFrame, display its head, print a concise summary, and finally show the count of missing values for each column.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf4b1515",
        "outputId": "d3b81f3c-9981-489a-fe1c-dfb463b0f2a7"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/AutoInsurance.csv')\n",
        "print(\"Dataset loaded successfully. Displaying the first 5 rows:\")\n",
        "# Display the first 5 rows\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nConcise summary of the DataFrame:\")\n",
        "# Print the concise summary\n",
        "print(df.info())\n",
        "\n",
        "print(\"\\nNumber of missing values per column:\")\n",
        "# Print the number of missing values for each column\n",
        "print(df.isnull().sum())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded successfully. Displaying the first 5 rows:\n",
            "  Customer       State  Customer Lifetime Value Response  Coverage Education  \\\n",
            "0  BU79786  Washington              2763.519279       No     Basic  Bachelor   \n",
            "1  QZ44356     Arizona              6979.535903       No  Extended  Bachelor   \n",
            "2  AI49188      Nevada             12887.431650       No   Premium  Bachelor   \n",
            "3  WW63253  California              7645.861827       No     Basic  Bachelor   \n",
            "4  HB64268  Washington              2813.692575       No     Basic  Bachelor   \n",
            "\n",
            "  Effective To Date EmploymentStatus Gender  Income  ...  \\\n",
            "0           2/24/11         Employed      F   56274  ...   \n",
            "1           1/31/11       Unemployed      F       0  ...   \n",
            "2           2/19/11         Employed      F   48767  ...   \n",
            "3           1/20/11       Unemployed      M       0  ...   \n",
            "4          3/2/2011         Employed      M   43836  ...   \n",
            "\n",
            "  Months Since Policy Inception Number of Open Complaints  Number of Policies  \\\n",
            "0                             5                         0                   1   \n",
            "1                            42                         0                   8   \n",
            "2                            38                         0                   2   \n",
            "3                            65                         0                   7   \n",
            "4                            44                         0                   1   \n",
            "\n",
            "      Policy Type        Policy  Renew Offer Type  Sales Channel  \\\n",
            "0  Corporate Auto  Corporate L3            Offer1          Agent   \n",
            "1   Personal Auto   Personal L3            Offer3          Agent   \n",
            "2   Personal Auto   Personal L3            Offer1          Agent   \n",
            "3  Corporate Auto  Corporate L2            Offer1    Call Center   \n",
            "4   Personal Auto   Personal L1            Offer1          Agent   \n",
            "\n",
            "  Total Claim Amount  Vehicle Class Vehicle Size  \n",
            "0         384.811147   Two-Door Car      Medsize  \n",
            "1        1131.464935  Four-Door Car      Medsize  \n",
            "2         566.472247   Two-Door Car      Medsize  \n",
            "3         529.881344            SUV      Medsize  \n",
            "4         138.130879  Four-Door Car      Medsize  \n",
            "\n",
            "[5 rows x 24 columns]\n",
            "\n",
            "Concise summary of the DataFrame:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9134 entries, 0 to 9133\n",
            "Data columns (total 24 columns):\n",
            " #   Column                         Non-Null Count  Dtype  \n",
            "---  ------                         --------------  -----  \n",
            " 0   Customer                       9134 non-null   object \n",
            " 1   State                          9134 non-null   object \n",
            " 2   Customer Lifetime Value        9134 non-null   float64\n",
            " 3   Response                       9134 non-null   object \n",
            " 4   Coverage                       9134 non-null   object \n",
            " 5   Education                      9134 non-null   object \n",
            " 6   Effective To Date              9134 non-null   object \n",
            " 7   EmploymentStatus               9134 non-null   object \n",
            " 8   Gender                         9134 non-null   object \n",
            " 9   Income                         9134 non-null   int64  \n",
            " 10  Location Code                  9134 non-null   object \n",
            " 11  Marital Status                 9134 non-null   object \n",
            " 12  Monthly Premium Auto           9134 non-null   int64  \n",
            " 13  Months Since Last Claim        9134 non-null   int64  \n",
            " 14  Months Since Policy Inception  9134 non-null   int64  \n",
            " 15  Number of Open Complaints      9134 non-null   int64  \n",
            " 16  Number of Policies             9134 non-null   int64  \n",
            " 17  Policy Type                    9134 non-null   object \n",
            " 18  Policy                         9134 non-null   object \n",
            " 19  Renew Offer Type               9134 non-null   object \n",
            " 20  Sales Channel                  9134 non-null   object \n",
            " 21  Total Claim Amount             9134 non-null   float64\n",
            " 22  Vehicle Class                  9134 non-null   object \n",
            " 23  Vehicle Size                   9134 non-null   object \n",
            "dtypes: float64(2), int64(6), object(16)\n",
            "memory usage: 1.7+ MB\n",
            "None\n",
            "\n",
            "Number of missing values per column:\n",
            "Customer                         0\n",
            "State                            0\n",
            "Customer Lifetime Value          0\n",
            "Response                         0\n",
            "Coverage                         0\n",
            "Education                        0\n",
            "Effective To Date                0\n",
            "EmploymentStatus                 0\n",
            "Gender                           0\n",
            "Income                           0\n",
            "Location Code                    0\n",
            "Marital Status                   0\n",
            "Monthly Premium Auto             0\n",
            "Months Since Last Claim          0\n",
            "Months Since Policy Inception    0\n",
            "Number of Open Complaints        0\n",
            "Number of Policies               0\n",
            "Policy Type                      0\n",
            "Policy                           0\n",
            "Renew Offer Type                 0\n",
            "Sales Channel                    0\n",
            "Total Claim Amount               0\n",
            "Vehicle Class                    0\n",
            "Vehicle Size                     0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7055602e"
      },
      "source": [
        "## Data Preprocessing and Feature Engineering\n",
        "\n",
        "### Subtask:\n",
        "Clean the data by handling missing values (if any), encoding categorical features (e.g., one-hot encoding), scaling numerical features, and preparing the target variable (Customer Lifetime Value) and features for model training. This step will also involve identifying and potentially dropping irrelevant columns.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0f48042"
      },
      "source": [
        "**Reasoning**:\n",
        "First, I will drop the 'Customer' and 'Effective To Date' columns as they are identified as irrelevant for model training, and then separate the target variable 'Customer Lifetime Value' from the features into 'y' and 'X' respectively, as instructed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "315f3cce",
        "outputId": "2e946e2e-0fff-428c-924b-0f70516f33e6"
      },
      "source": [
        "print(\"Original DataFrame shape:\", df.shape)\n",
        "# Drop irrelevant columns\n",
        "df = df.drop(['Customer', 'Effective To Date'], axis=1)\n",
        "print(\"DataFrame shape after dropping irrelevant columns:\", df.shape)\n",
        "\n",
        "# Separate target variable (y) and features (X)\n",
        "y = df['Customer Lifetime Value']\n",
        "X = df.drop('Customer Lifetime Value', axis=1)\n",
        "\n",
        "print(\"\\nShape of X (features):\")\n",
        "print(X.shape)\n",
        "print(\"Shape of y (target):\")\n",
        "print(y.shape)\n",
        "print(\"First 5 rows of y:\")\n",
        "print(y.head())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame shape: (9134, 24)\n",
            "DataFrame shape after dropping irrelevant columns: (9134, 22)\n",
            "\n",
            "Shape of X (features):\n",
            "(9134, 21)\n",
            "Shape of y (target):\n",
            "(9134,)\n",
            "First 5 rows of y:\n",
            "0     2763.519279\n",
            "1     6979.535903\n",
            "2    12887.431650\n",
            "3     7645.861827\n",
            "4     2813.692575\n",
            "Name: Customer Lifetime Value, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54747e70"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the irrelevant columns have been dropped and the target variable separated, I will identify the categorical and numerical features within the feature DataFrame `X` as per the next instruction. This involves iterating through the columns of `X` and classifying them based on their data types.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1cff74c",
        "outputId": "4a3c8d75-4229-498b-d6e9-026fa2c191a6"
      },
      "source": [
        "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
        "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "print(\"Categorical Features:\", categorical_features)\n",
        "print(\"Number of Categorical Features:\", len(categorical_features))\n",
        "print(\"\\nNumerical Features:\", numerical_features)\n",
        "print(\"Number of Numerical Features:\", len(numerical_features))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Categorical Features: ['State', 'Response', 'Coverage', 'Education', 'EmploymentStatus', 'Gender', 'Location Code', 'Marital Status', 'Policy Type', 'Policy', 'Renew Offer Type', 'Sales Channel', 'Vehicle Class', 'Vehicle Size']\n",
            "Number of Categorical Features: 14\n",
            "\n",
            "Numerical Features: ['Income', 'Monthly Premium Auto', 'Months Since Last Claim', 'Months Since Policy Inception', 'Number of Open Complaints', 'Number of Policies', 'Total Claim Amount']\n",
            "Number of Numerical Features: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "311895f9"
      },
      "source": [
        "**Reasoning**:\n",
        "Following the identification of categorical and numerical features, I will now apply one-hot encoding to the categorical features using `pd.get_dummies()` with `drop_first=True` to prevent multicollinearity, as instructed. Then, I will replace the original categorical columns in `X` with these newly encoded columns.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc1bfb4d",
        "outputId": "2461e4e6-825d-49af-c77b-6bc8b2374649"
      },
      "source": [
        "print(\"Shape of X before one-hot encoding:\", X.shape)\n",
        "\n",
        "# Apply one-hot encoding to categorical features\n",
        "X_categorical_encoded = pd.get_dummies(X[categorical_features], drop_first=True)\n",
        "\n",
        "# Drop original categorical columns from X and concatenate with encoded features\n",
        "X = X.drop(columns=categorical_features)\n",
        "X = pd.concat([X, X_categorical_encoded], axis=1)\n",
        "\n",
        "print(\"Shape of X after one-hot encoding:\", X.shape)\n",
        "print(\"First 5 rows of X after one-hot encoding:\")\n",
        "print(X.head())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X before one-hot encoding: (9134, 21)\n",
            "Shape of X after one-hot encoding: (9134, 50)\n",
            "First 5 rows of X after one-hot encoding:\n",
            "   Income  Monthly Premium Auto  Months Since Last Claim  \\\n",
            "0   56274                    69                       32   \n",
            "1       0                    94                       13   \n",
            "2   48767                   108                       18   \n",
            "3       0                   106                       18   \n",
            "4   43836                    73                       12   \n",
            "\n",
            "   Months Since Policy Inception  Number of Open Complaints  \\\n",
            "0                              5                          0   \n",
            "1                             42                          0   \n",
            "2                             38                          0   \n",
            "3                             65                          0   \n",
            "4                             44                          0   \n",
            "\n",
            "   Number of Policies  Total Claim Amount  State_California  State_Nevada  \\\n",
            "0                   1          384.811147             False         False   \n",
            "1                   8         1131.464935             False         False   \n",
            "2                   2          566.472247             False          True   \n",
            "3                   7          529.881344              True         False   \n",
            "4                   1          138.130879             False         False   \n",
            "\n",
            "   State_Oregon  ...  Sales Channel_Branch  Sales Channel_Call Center  \\\n",
            "0         False  ...                 False                      False   \n",
            "1         False  ...                 False                      False   \n",
            "2         False  ...                 False                      False   \n",
            "3         False  ...                 False                       True   \n",
            "4         False  ...                 False                      False   \n",
            "\n",
            "   Sales Channel_Web  Vehicle Class_Luxury Car  Vehicle Class_Luxury SUV  \\\n",
            "0              False                     False                     False   \n",
            "1              False                     False                     False   \n",
            "2              False                     False                     False   \n",
            "3              False                     False                     False   \n",
            "4              False                     False                     False   \n",
            "\n",
            "   Vehicle Class_SUV  Vehicle Class_Sports Car  Vehicle Class_Two-Door Car  \\\n",
            "0              False                     False                        True   \n",
            "1              False                     False                       False   \n",
            "2              False                     False                        True   \n",
            "3               True                     False                       False   \n",
            "4              False                     False                       False   \n",
            "\n",
            "   Vehicle Size_Medsize  Vehicle Size_Small  \n",
            "0                  True               False  \n",
            "1                  True               False  \n",
            "2                  True               False  \n",
            "3                  True               False  \n",
            "4                  True               False  \n",
            "\n",
            "[5 rows x 50 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3cf36c5"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that categorical features are encoded, the next step is to scale the numerical features as per the instructions. I will use `StandardScaler` to fit and transform the numerical columns in `X`, and then update `X` with these scaled values.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64162b98",
        "outputId": "2ca21355-3476-49ea-cd82-3a92b34fd81a"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "print(\"Shape of X before scaling numerical features:\", X.shape)\n",
        "\n",
        "# Instantiate StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Apply StandardScaler to numerical features\n",
        "X[numerical_features] = scaler.fit_transform(X[numerical_features])\n",
        "\n",
        "print(\"Shape of X after scaling numerical features:\", X.shape)\n",
        "print(\"First 5 rows of X after scaling numerical features:\")\n",
        "print(X.head())\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X before scaling numerical features: (9134, 50)\n",
            "Shape of X after scaling numerical features: (9134, 50)\n",
            "First 5 rows of X after scaling numerical features:\n",
            "     Income  Monthly Premium Auto  Months Since Last Claim  \\\n",
            "0  0.612827             -0.703925                 1.678099   \n",
            "1 -1.239617              0.022691                -0.208186   \n",
            "2  0.365710              0.429596                 0.288205   \n",
            "3 -1.239617              0.371467                 0.288205   \n",
            "4  0.203390             -0.587666                -0.307465   \n",
            "\n",
            "   Months Since Policy Inception  Number of Open Complaints  \\\n",
            "0                      -1.543287                   -0.42225   \n",
            "1                      -0.217334                   -0.42225   \n",
            "2                      -0.360680                   -0.42225   \n",
            "3                       0.606907                   -0.42225   \n",
            "4                      -0.145661                   -0.42225   \n",
            "\n",
            "   Number of Policies  Total Claim Amount  State_California  State_Nevada  \\\n",
            "0           -0.822648           -0.169640             False         False   \n",
            "1            2.106160            2.400737             False         False   \n",
            "2           -0.404247            0.455734             False          True   \n",
            "3            1.687759            0.329769              True         False   \n",
            "4           -0.822648           -1.018843             False         False   \n",
            "\n",
            "   State_Oregon  ...  Sales Channel_Branch  Sales Channel_Call Center  \\\n",
            "0         False  ...                 False                      False   \n",
            "1         False  ...                 False                      False   \n",
            "2         False  ...                 False                      False   \n",
            "3         False  ...                 False                       True   \n",
            "4         False  ...                 False                      False   \n",
            "\n",
            "   Sales Channel_Web  Vehicle Class_Luxury Car  Vehicle Class_Luxury SUV  \\\n",
            "0              False                     False                     False   \n",
            "1              False                     False                     False   \n",
            "2              False                     False                     False   \n",
            "3              False                     False                     False   \n",
            "4              False                     False                     False   \n",
            "\n",
            "   Vehicle Class_SUV  Vehicle Class_Sports Car  Vehicle Class_Two-Door Car  \\\n",
            "0              False                     False                        True   \n",
            "1              False                     False                       False   \n",
            "2              False                     False                        True   \n",
            "3               True                     False                       False   \n",
            "4              False                     False                       False   \n",
            "\n",
            "   Vehicle Size_Medsize  Vehicle Size_Small  \n",
            "0                  True               False  \n",
            "1                  True               False  \n",
            "2                  True               False  \n",
            "3                  True               False  \n",
            "4                  True               False  \n",
            "\n",
            "[5 rows x 50 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f93c53d"
      },
      "source": [
        "## Split Data into Training and Testing Sets\n",
        "\n",
        "### Subtask:\n",
        "Divide the preprocessed dataset into training and testing sets to evaluate model performance on unseen data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "357d5912"
      },
      "source": [
        "**Reasoning**:\n",
        "To divide the preprocessed dataset into training and testing sets as instructed, I will first import the `train_test_split` function from `sklearn.model_selection` and then apply it to the `X` and `y` DataFrames with a `test_size` of 0.2 and a `random_state` of 42.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2949d2d5",
        "outputId": "1c00e37b-390c-4596-b8d7-41e2b6787d9f"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of X_test:\", X_test.shape)\n",
        "print(\"Shape of y_train:\", y_train.shape)\n",
        "print(\"Shape of y_test:\", y_test.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train: (7307, 50)\n",
            "Shape of X_test: (1827, 50)\n",
            "Shape of y_train: (7307,)\n",
            "Shape of y_test: (1827,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9844024c"
      },
      "source": [
        "## Train and Evaluate Linear Regression Model\n",
        "\n",
        "### Subtask:\n",
        "Train a Linear Regression model on the training data. Then, evaluate its performance by calculating and printing the R-squared scores for both the training and testing sets. Analyze these scores to check for overfitting.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae99d819"
      },
      "source": [
        "**Reasoning**:\n",
        "To train and evaluate the Linear Regression model, I will import the necessary classes, instantiate the model, fit it to the training data, make predictions, and then calculate and print the R-squared scores for both training and testing sets as instructed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3997aae3",
        "outputId": "a1859447-e668-4476-8a39-a9bb885596ff"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Instantiate Linear Regression model\n",
        "linear_model = LinearRegression()\n",
        "\n",
        "# Fit the model to the training data\n",
        "linear_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on training and testing sets\n",
        "y_pred_train_linear = linear_model.predict(X_train)\n",
        "y_pred_test_linear = linear_model.predict(X_test)\n",
        "\n",
        "# Calculate R-squared for training set\n",
        "r2_train_linear = r2_score(y_train, y_pred_train_linear)\n",
        "print(f\"Linear Regression Training R-squared: {r2_train_linear:.4f}\")\n",
        "\n",
        "# Calculate R-squared for testing set\n",
        "r2_test_linear = r2_score(y_test, y_pred_test_linear)\n",
        "print(f\"Linear Regression Testing R-squared: {r2_test_linear:.4f}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression Training R-squared: 0.1714\n",
            "Linear Regression Testing R-squared: 0.1551\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "accdd977"
      },
      "source": [
        "The R-squared score for the training set is 0.1714, and for the testing set, it is 0.1551. These scores are quite low, indicating that the Linear Regression model does not explain a large proportion of the variance in 'Customer Lifetime Value'. The scores for training and testing are close, suggesting that the model is not overfitting (i.e., it's not performing significantly better on the training data than on unseen data). However, the overall low R-squared values suggest that the model is underfitting, meaning it is too simple to capture the underlying patterns in the data effectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e0c39cf"
      },
      "source": [
        "## Train and Evaluate Random Forest Regressor Model\n",
        "\n",
        "### Subtask:\n",
        "Train a Random Forest Regressor model on the training data. Then, evaluate its performance by calculating and printing the R-squared scores for both the training and testing sets. Analyze these scores to check for overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05536be6"
      },
      "source": [
        "**Reasoning**:\n",
        "Following the introduction of the subtask for Random Forest Regressor, I will now import the necessary libraries, instantiate the Random Forest Regressor model, train it on the `X_train` and `y_train` data, and then make predictions on both the training and testing sets to prepare for R-squared score calculation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72c4fd1c",
        "outputId": "bf805640-98f8-4781-e517-5e0a2f9f4c4d"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Instantiate Random Forest Regressor model\n",
        "rf_model = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# Fit the model to the training data\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on training and testing sets\n",
        "y_pred_train_rf = rf_model.predict(X_train)\n",
        "y_pred_test_rf = rf_model.predict(X_test)\n",
        "\n",
        "print(\"Random Forest Regressor model trained and predictions made.\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Regressor model trained and predictions made.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51608541"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the Random Forest Regressor model has been trained and predictions have been made, I will calculate and print the R-squared scores for both the training and testing sets to evaluate its performance, as instructed in the subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96b4fe91",
        "outputId": "0f3fb015-8c83-4cbf-aee9-22e528b69938"
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Calculate R-squared for training set\n",
        "r2_train_rf = r2_score(y_train, y_pred_train_rf)\n",
        "print(f\"Random Forest Regressor Training R-squared: {r2_train_rf:.4f}\")\n",
        "\n",
        "# Calculate R-squared for testing set\n",
        "r2_test_rf = r2_score(y_test, y_pred_test_rf)\n",
        "print(f\"Random Forest Regressor Testing R-squared: {r2_test_rf:.4f}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Regressor Training R-squared: 0.9596\n",
            "Random Forest Regressor Testing R-squared: 0.6901\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cc03467"
      },
      "source": [
        "The Random Forest Regressor achieved a training R-squared score of 0.9596 and a testing R-squared score of 0.6901. The high R-squared on the training set (0.9596) suggests that the model fits the training data very well. However, there is a significant drop in performance on the testing set (0.6901).\n",
        "\n",
        "This discrepancy indicates that the Random Forest Regressor is likely overfitting the training data. While it captures complex patterns in the training data, it does not generalize as effectively to unseen data. This suggests that the model might be too complex for the given dataset or that hyperparameter tuning is needed to reduce overfitting and improve its generalization capabilities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c02aba9"
      },
      "source": [
        "## Train and Evaluate Gradient Boosting Regressor Model\n",
        "\n",
        "### Subtask:\n",
        "Train a Gradient Boosting Regressor model on the training data. Then, evaluate its performance by calculating and printing the R-squared scores for both the training and testing sets. Analyze these scores to check for overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f35a8a8e"
      },
      "source": [
        "**Reasoning**:\n",
        "Following the introduction of the subtask for the Gradient Boosting Regressor, I will now import the necessary libraries, instantiate the Gradient Boosting Regressor model, train it on the `X_train` and `y_train` data, and then make predictions on both the training and testing sets.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "156b989c",
        "outputId": "cc1b7036-d128-4772-83d2-dfb7789ccb9d"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "# Instantiate Gradient Boosting Regressor model\n",
        "gbr_model = GradientBoostingRegressor(random_state=42)\n",
        "\n",
        "# Fit the model to the training data\n",
        "gbr_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on training and testing sets\n",
        "y_pred_train_gbr = gbr_model.predict(X_train)\n",
        "y_pred_test_gbr = gbr_model.predict(X_test)\n",
        "\n",
        "print(\"Gradient Boosting Regressor model trained and predictions made.\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting Regressor model trained and predictions made.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47c5702e"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the Gradient Boosting Regressor model has been trained and predictions have been made, I will calculate and print the R-squared scores for both the training and testing sets to evaluate its performance, as instructed in the subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f135b6a",
        "outputId": "d9235ca8-fb34-4c8e-fec6-76824defeb43"
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Calculate R-squared for training set\n",
        "r2_train_gbr = r2_score(y_train, y_pred_train_gbr)\n",
        "print(f\"Gradient Boosting Regressor Training R-squared: {r2_train_gbr:.4f}\")\n",
        "\n",
        "# Calculate R-squared for testing set\n",
        "r2_test_gbr = r2_score(y_test, y_pred_test_gbr)\n",
        "print(f\"Gradient Boosting Regressor Testing R-squared: {r2_test_gbr:.4f}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting Regressor Training R-squared: 0.7349\n",
            "Gradient Boosting Regressor Testing R-squared: 0.6662\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bc2302f"
      },
      "source": [
        "The Gradient Boosting Regressor achieved a training R-squared score of 0.7349 and a testing R-squared score of 0.6662. Both scores are significantly higher than those from the Linear Regression model, indicating a much better fit to the data. Compared to the Random Forest Regressor, the training R-squared is lower (0.7349 vs 0.9596), but the testing R-squared is somewhat comparable (0.6662 vs 0.6901). The difference between the training and testing R-squared for the Gradient Boosting Regressor is smaller than that of the Random Forest Regressor, suggesting less overfitting. While there is still a drop in performance from training to testing, it's less pronounced, indicating better generalization than the Random Forest model without extensive hyperparameter tuning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "357342e2"
      },
      "source": [
        "## Compare Models and Select the Best\n",
        "\n",
        "### Subtask:\n",
        "Compare the R-squared scores of the Linear Regression, Random Forest Regressor, and Gradient Boosting Regressor models on both the training and testing sets. Select the best performing model based on its generalization capabilities (i.e., testing R-squared score) and note the chosen model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2265d09f"
      },
      "source": [
        "### Model Comparison and Selection\n",
        "\n",
        "Let's summarize the R-squared scores for all models:\n",
        "\n",
        "*   **Linear Regression**\n",
        "    *   Training R-squared: 0.1714\n",
        "    *   Testing R-squared: 0.1551\n",
        "    *   *Analysis*: Very low R-squared, indicating underfitting. No significant overfitting.\n",
        "\n",
        "*   **Random Forest Regressor**\n",
        "    *   Training R-squared: 0.9596\n",
        "    *   Testing R-squared: 0.6901\n",
        "    *   *Analysis*: High training R-squared but a considerable drop on the testing set suggests overfitting. However, it achieved the highest testing R-squared.\n",
        "\n",
        "*   **Gradient Boosting Regressor**\n",
        "    *   Training R-squared: 0.7349\n",
        "    *   Testing R-squared: 0.6662\n",
        "    *   *Analysis*: Good training R-squared with a smaller drop on the testing set compared to Random Forest, indicating better generalization and less overfitting. Its testing R-squared is slightly lower than Random Forest.\n",
        "\n",
        "**Conclusion:**\n",
        "\n",
        "Based on the testing R-squared scores, the **Random Forest Regressor** model performs the best with a testing R-squared of **0.6901**. Although it shows signs of overfitting (large difference between training and testing scores), it generalizes better to unseen data compared to the other models, as evidenced by its superior testing R-squared. The Gradient Boosting Regressor is a close second with 0.6662, showing better generalization characteristics (less overfitting) but slightly lower predictive power on the test set for this specific run. For this task, we prioritize the highest predictive performance on unseen data (testing R-squared)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40c27ed4"
      },
      "source": [
        "## Deploy Best Model with Gradio\n",
        "\n",
        "### Subtask:\n",
        "Create a user-friendly web interface using Gradio to deploy the selected best model, allowing users to input new data and get predictions for Customer Lifetime Value.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b27b356"
      },
      "source": [
        "**Reasoning**:\n",
        "First, I will identify the best performing model based on the R-squared scores from the previous steps, which is the Random Forest Regressor. Then, I will import the `gradio` library and define a `predict_clv` function that takes all relevant features as input, preprocesses them (one-hot encoding categorical features, scaling numerical features), and uses the selected `rf_model` to make a prediction. Finally, I will create a Gradio interface with appropriate input components for each feature and launch it, as instructed by the subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "0cc51bf4",
        "outputId": "8361e67f-c306-418e-9350-c00f2d7f1a1a"
      },
      "source": [
        "import gradio as gr\n",
        "import pandas as pd\n",
        "\n",
        "# Best performing model is Random Forest Regressor (rf_model) based on testing R-squared\n",
        "# (r2_test_rf: 0.6901, r2_test_gbr: 0.6662, r2_test_linear: 0.1551)\n",
        "\n",
        "# Get unique values for dropdowns from the 'df' (which is the one after dropping irrelevant columns but before one-hot encoding)\n",
        "categorical_unique_values = {}\n",
        "for col in categorical_features:\n",
        "    categorical_unique_values[col] = df[col].unique().tolist()\n",
        "\n",
        "def predict_clv(*args):\n",
        "    # The order of args must match the order of feature names defined for the Gradio interface\n",
        "    # numerical_features: 'Income', 'Monthly Premium Auto', 'Months Since Last Claim', 'Months Since Policy Inception', 'Number of Open Complaints', 'Number of Policies', 'Total Claim Amount'\n",
        "    # categorical_features: 'State', 'Response', 'Coverage', 'Education', 'EmploymentStatus', 'Gender', 'Location Code', 'Marital Status', 'Policy Type', 'Policy', 'Renew Offer Type', 'Sales Channel', 'Vehicle Class', 'Vehicle Size'\n",
        "\n",
        "    input_data = {}\n",
        "    arg_idx = 0\n",
        "    # Populate numerical features\n",
        "    for feature in numerical_features:\n",
        "        input_data[feature] = [args[arg_idx]]\n",
        "        arg_idx += 1\n",
        "    # Populate categorical features\n",
        "    for feature in categorical_features:\n",
        "        input_data[feature] = [args[arg_idx]]\n",
        "        arg_idx += 1\n",
        "\n",
        "    input_df = pd.DataFrame(input_data)\n",
        "\n",
        "    # Apply one-hot encoding to categorical features\n",
        "    input_categorical_encoded = pd.get_dummies(input_df[categorical_features], drop_first=True)\n",
        "\n",
        "    # Prepare the input_df for scaling and prediction\n",
        "    # Drop original categorical columns from the input_df\n",
        "    input_df_processed = input_df.drop(columns=categorical_features)\n",
        "    # Concatenate with encoded features\n",
        "    input_df_processed = pd.concat([input_df_processed, input_categorical_encoded], axis=1)\n",
        "\n",
        "    # Reindex to ensure all columns from training (X.columns) are present and in the correct order\n",
        "    # Fill missing columns (for categories not present in the single input row) with 0\n",
        "    input_df_processed = input_df_processed.reindex(columns=X.columns, fill_value=0)\n",
        "\n",
        "    # Scale numerical features using the pre-fitted scaler\n",
        "    # Ensure 'Income' column exists in input_df_processed before scaling\n",
        "    if 'Income' in input_df_processed.columns:\n",
        "        input_df_processed[numerical_features] = scaler.transform(input_df_processed[numerical_features])\n",
        "    else:\n",
        "        # Handle case where numerical_features might not be directly in the reindexed DataFrame if X.columns didn't include them all\n",
        "        # This scenario is unlikely given how X was created, but added for robustness\n",
        "        for num_feat in numerical_features:\n",
        "            if num_feat in input_df_processed.columns:\n",
        "                input_df_processed[num_feat] = scaler.transform(input_df_processed[[num_feat]])\n",
        "\n",
        "    # Make prediction using the best model (rf_model)\n",
        "    prediction = rf_model.predict(input_df_processed)[0] # [0] to get the single scalar value\n",
        "\n",
        "    return f\"Predicted Customer Lifetime Value: ${prediction:.2f}\"\n",
        "\n",
        "# Create Gradio interface inputs\n",
        "inputs = []\n",
        "for feature in numerical_features:\n",
        "    inputs.append(gr.Number(label=feature))\n",
        "\n",
        "for feature in categorical_features:\n",
        "    inputs.append(gr.Dropdown(choices=categorical_unique_values[feature], label=feature))\n",
        "\n",
        "output = gr.Textbox(label=\"Predicted Customer Lifetime Value\")\n",
        "\n",
        "# Launch the Gradio interface\n",
        "gr.Interface(\n",
        "    fn=predict_clv,\n",
        "    inputs=inputs,\n",
        "    outputs=output,\n",
        "    title=\"Customer Lifetime Value Prediction\",\n",
        "    description=\"Enter customer details to predict their Customer Lifetime Value.\"\n",
        ").launch()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://f96414a025478a3c25.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://f96414a025478a3c25.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0bc9991"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Summarize the entire process, including the data preprocessing steps, the performance of each model, the rationale for selecting the best model, and a demonstration of the deployed Gradio interface for predicting Customer Lifetime Value.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b855efb2"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   **Initial Data Inspection**: The `AutoInsurance.csv` dataset, comprising 9134 entries across 24 columns, was loaded successfully. It was found to be clean, with no missing values in any column. Data types included 2 float, 6 integer, and 16 object (categorical) columns.\n",
        "*   **Data Preprocessing**:\n",
        "    *   Irrelevant columns 'Customer' and 'Effective To Date' were dropped.\n",
        "    *   The target variable, 'Customer Lifetime Value', was separated.\n",
        "    *   14 categorical features were identified and one-hot encoded (using `drop_first=True`), expanding the feature set from 21 to 50 columns.\n",
        "    *   7 numerical features were identified and scaled using `StandardScaler`.\n",
        "*   **Data Splitting**: The preprocessed data was split into training (7307 samples) and testing (1827 samples) sets with an 80/20 ratio.\n",
        "*   **Model Performance Comparison**:\n",
        "    *   **Linear Regression**: Showed very low R-squared scores (Training: 0.1714, Testing: 0.1551), indicating severe underfitting.\n",
        "    *   **Random Forest Regressor**: Achieved a high training R-squared (0.9596) but a significantly lower testing R-squared (0.6901), suggesting overfitting. However, it delivered the highest predictive performance on unseen data.\n",
        "    *   **Gradient Boosting Regressor**: Performed better than Linear Regression (Training R-squared: 0.7349, Testing R-squared: 0.6662). It exhibited less overfitting than the Random Forest, but its testing R-squared was slightly lower.\n",
        "*   **Best Model Selection**: The **Random Forest Regressor** was selected as the best model for deployment due to its highest testing R-squared score of **0.6901**, demonstrating the best predictive power on unseen data among the evaluated models, despite showing signs of overfitting.\n",
        "*   **Model Deployment**: The selected Random Forest Regressor model was successfully deployed using a Gradio web interface. The interface allows users to input numerical and categorical customer details, which are preprocessed using the same steps (one-hot encoding, scaling) as during training, to predict Customer Lifetime Value.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   **Overfitting Mitigation**: While the Random Forest Regressor had the best testing performance, the notable difference between its training (0.9596) and testing (0.6901) R-squared scores indicates overfitting. Further hyperparameter tuning (e.g., using GridSearchCV or RandomizedSearchCV) or techniques like pruning could be explored to improve its generalization capabilities and potentially reduce this gap without sacrificing too much predictive power.\n",
        "*   **Feature Engineering Exploration**: Given the relatively low R-squared values across all models (even the best at 0.6901), exploring additional feature engineering techniques, such as creating interaction terms or polynomial features, could enhance the models' ability to capture more complex relationships in the data and improve predictive accuracy.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d81d4b10"
      },
      "source": [
        "# Task\n",
        "Improve the prediction of \"Customer Lifetime Value\" using the `AutoInsurance.csv` dataset by identifying and handling outliers in numerical features, retraining and evaluating Linear Regression, Random Forest Regressor, and Gradient Boosting Regressor models on the outlier-adjusted data, selecting the best performing model, and deploying it with a Gradio interface. Finally, summarize the impact of outlier removal on model performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29d6c163"
      },
      "source": [
        "## Identify and Remove Outliers\n",
        "\n",
        "### Subtask:\n",
        "Identify outliers in the numerical features of the dataset using an appropriate statistical method (e.g., IQR) and then remove or cap them to create a cleaned dataset. This step will use the `X` and `y` from the previous preprocessing steps.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a6c1279"
      },
      "source": [
        "**Reasoning**:\n",
        "To identify and remove outliers using the IQR method, I will first initialize an empty boolean mask. Then, I will iterate through each numerical feature, calculate its Q1, Q3, and IQR, define the outlier bounds, and update the mask to mark outliers. Finally, I will use this mask to filter both `X` and `y` to create `X_cleaned` and `y_cleaned`, and print their new shapes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36e2a7e7",
        "outputId": "05051f7c-18ee-4dca-e131-1a0927f4c7cd"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# 1. Initialize an empty boolean series `outlier_mask`\n",
        "outlier_mask = pd.Series([False] * len(X), index=X.index)\n",
        "\n",
        "# 2. Iterate through each numerical feature\n",
        "for feature in numerical_features:\n",
        "    # 3. Calculate the first quartile (Q1) and third quartile (Q3)\n",
        "    Q1 = X[feature].quantile(0.25)\n",
        "    Q3 = X[feature].quantile(0.75)\n",
        "\n",
        "    # 4. Calculate the Interquartile Range (IQR)\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    # 5. Determine the lower bound and upper bound for outlier detection\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    # 6. Update the `outlier_mask` to mark `True` for any row where the feature's value is an outlier\n",
        "    outlier_mask = outlier_mask | ((X[feature] < lower_bound) | (X[feature] > upper_bound))\n",
        "\n",
        "# 7. Create a new DataFrame `X_cleaned` by filtering `X` using the inverse of the `outlier_mask`\n",
        "X_cleaned = X[~outlier_mask]\n",
        "\n",
        "# 8. Create a new Series `y_cleaned` by filtering `y` using the inverse of the `outlier_mask`\n",
        "y_cleaned = y[~outlier_mask]\n",
        "\n",
        "# 9. Print the shape of `X_cleaned` and `y_cleaned`\n",
        "print(f\"Original shape of X: {X.shape}\")\n",
        "print(f\"Shape of X_cleaned after outlier removal: {X_cleaned.shape}\")\n",
        "print(f\"Original shape of y: {y.shape}\")\n",
        "print(f\"Shape of y_cleaned after outlier removal: {y_cleaned.shape}\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shape of X: (9134, 50)\n",
            "Shape of X_cleaned after outlier removal: (6436, 50)\n",
            "Original shape of y: (9134,)\n",
            "Shape of y_cleaned after outlier removal: (6436,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5cfc695"
      },
      "source": [
        "## Re-split Data into Training and Testing Sets (Outlier-Adjusted)\n",
        "\n",
        "### Subtask:\n",
        "Divide the outlier-adjusted dataset (X_cleaned, y_cleaned) into new training and testing sets to prepare for re-training the models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe8e8319"
      },
      "source": [
        "**Reasoning**:\n",
        "To divide the outlier-adjusted dataset into training and testing sets as instructed, I will use the `train_test_split` function from `sklearn.model_selection` with a `test_size` of 0.2 and a `random_state` of 42, then print the shapes of the resulting datasets.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64576555",
        "outputId": "2c0e844e-59e1-4f46-a871-8a16086012ed"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the cleaned data into training and testing sets\n",
        "X_train_cleaned, X_test_cleaned, y_train_cleaned, y_test_cleaned = train_test_split(X_cleaned, y_cleaned, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Shape of X_train_cleaned:\", X_train_cleaned.shape)\n",
        "print(\"Shape of X_test_cleaned:\", X_test_cleaned.shape)\n",
        "print(\"Shape of y_train_cleaned:\", y_train_cleaned.shape)\n",
        "print(\"Shape of y_test_cleaned:\", y_test_cleaned.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train_cleaned: (5148, 50)\n",
            "Shape of X_test_cleaned: (1288, 50)\n",
            "Shape of y_train_cleaned: (5148,)\n",
            "Shape of y_test_cleaned: (1288,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7edf243"
      },
      "source": [
        "## Retrain and Evaluate Linear Regression Model (Outlier-Adjusted)\n",
        "\n",
        "### Subtask:\n",
        "Retrain the Linear Regression model on the outlier-adjusted training data and evaluate its performance using R-squared scores for both training and testing sets. Analyze for overfitting/underfitting.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "485714a8"
      },
      "source": [
        "**Reasoning**:\n",
        "To retrain and evaluate the Linear Regression model on the outlier-adjusted data, I will import necessary classes, instantiate the model, fit it to the cleaned training data, make predictions on both cleaned training and testing sets, and then calculate and print the R-squared scores for both.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "061ac26d",
        "outputId": "d56ce855-d5da-4a2f-f07c-12430e557eb1"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Instantiate Linear Regression model\n",
        "linear_model_cleaned = LinearRegression()\n",
        "\n",
        "# Fit the model to the cleaned training data\n",
        "linear_model_cleaned.fit(X_train_cleaned, y_train_cleaned)\n",
        "\n",
        "# Make predictions on cleaned training and testing sets\n",
        "y_pred_train_linear_cleaned = linear_model_cleaned.predict(X_train_cleaned)\n",
        "y_pred_test_linear_cleaned = linear_model_cleaned.predict(X_test_cleaned)\n",
        "\n",
        "# Calculate R-squared for cleaned training set\n",
        "r2_train_linear_cleaned = r2_score(y_train_cleaned, y_pred_train_linear_cleaned)\n",
        "print(f\"Linear Regression (Outlier-Adjusted) Training R-squared: {r2_train_linear_cleaned:.4f}\")\n",
        "\n",
        "# Calculate R-squared for cleaned testing set\n",
        "r2_test_linear_cleaned = r2_score(y_test_cleaned, y_pred_test_linear_cleaned)\n",
        "print(f\"Linear Regression (Outlier-Adjusted) Testing R-squared: {r2_test_linear_cleaned:.4f}\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression (Outlier-Adjusted) Training R-squared: 0.1110\n",
            "Linear Regression (Outlier-Adjusted) Testing R-squared: 0.0995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be21ee60"
      },
      "source": [
        "The Linear Regression model, after outlier removal, shows a training R-squared of 0.1110 and a testing R-squared of 0.0995. These scores are extremely low, even lower than the scores obtained before outlier removal (Training R-squared: 0.1714, Testing R-squared: 0.1551). This indicates that the Linear Regression model is still severely underfitting the data, meaning it is too simple to capture the underlying patterns, and the removal of outliers did not improve its performance; in fact, it slightly worsened it for this model. The very small difference between training and testing R-squared suggests no overfitting, but rather a consistent lack of fit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ded5a3e5"
      },
      "source": [
        "**Reasoning**:\n",
        "To retrain the Random Forest Regressor model on the outlier-adjusted data, I will import the necessary class, instantiate the model, fit it to the cleaned training data, and then make predictions on both the cleaned training and testing sets.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "712a5742",
        "outputId": "d123241b-1215-409f-bcfc-16ca4d64a35e"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Instantiate Random Forest Regressor model with the same random_state\n",
        "rf_model_cleaned = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# Fit the model to the cleaned training data\n",
        "rf_model_cleaned.fit(X_train_cleaned, y_train_cleaned)\n",
        "\n",
        "# Make predictions on cleaned training and testing sets\n",
        "y_pred_train_rf_cleaned = rf_model_cleaned.predict(X_train_cleaned)\n",
        "y_pred_test_rf_cleaned = rf_model_cleaned.predict(X_test_cleaned)\n",
        "\n",
        "print(\"Random Forest Regressor (Outlier-Adjusted) model trained and predictions made.\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Regressor (Outlier-Adjusted) model trained and predictions made.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa66b079"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the Random Forest Regressor model has been retrained on the outlier-adjusted data and predictions have been made, I will calculate and print the R-squared scores for both the cleaned training and testing sets to evaluate its performance, as instructed by the overarching task structure.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "333b42ad",
        "outputId": "dcbaab81-84be-4dec-debc-868f39d3024b"
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Calculate R-squared for cleaned training set\n",
        "r2_train_rf_cleaned = r2_score(y_train_cleaned, y_pred_train_rf_cleaned)\n",
        "print(f\"Random Forest Regressor (Outlier-Adjusted) Training R-squared: {r2_train_rf_cleaned:.4f}\")\n",
        "\n",
        "# Calculate R-squared for cleaned testing set\n",
        "r2_test_rf_cleaned = r2_score(y_test_cleaned, y_pred_test_rf_cleaned)\n",
        "print(f\"Random Forest Regressor (Outlier-Adjusted) Testing R-squared: {r2_test_rf_cleaned:.4f}\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Regressor (Outlier-Adjusted) Training R-squared: 0.9565\n",
            "Random Forest Regressor (Outlier-Adjusted) Testing R-squared: 0.7011\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf496638"
      },
      "source": [
        "The Random Forest Regressor model, after outlier removal, shows a training R-squared of 0.9565 and a testing R-squared of 0.7011.\n",
        "\n",
        "Compared to its performance before outlier removal (Training R-squared: 0.9596, Testing R-squared: 0.6901):\n",
        "*   **Training R-squared** slightly decreased (from 0.9596 to 0.9565), indicating a minimal change in its fit to the training data. The model still fits the training data very well.\n",
        "*   **Testing R-squared** slightly increased (from 0.6901 to 0.7011), suggesting a minor improvement in its generalization to unseen data after outliers were removed.\n",
        "\n",
        "While the model still shows a notable difference between its training and testing R-squared, indicating some level of overfitting, the improvement in the testing R-squared after outlier removal is a positive sign. This suggests that removing outliers helped the model generalize slightly better, even if the primary issue of overfitting remains a consideration for further hyperparameter tuning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "901d4f17"
      },
      "source": [
        "The Random Forest Regressor model, after outlier removal, shows a training R-squared of 0.9565 and a testing R-squared of 0.7011.\n",
        "\n",
        "Compared to its performance before outlier removal (Training R-squared: 0.9596, Testing R-squared: 0.6901):\n",
        "*   **Training R-squared** slightly decreased (from 0.9596 to 0.9565), indicating a minimal change in its fit to the training data. The model still fits the training data very well.\n",
        "*   **Testing R-squared** slightly increased (from 0.6901 to 0.7011), suggesting a minor improvement in its generalization to unseen data after outliers were removed.\n",
        "\n",
        "While the model still shows a notable difference between its training and testing R-squared, indicating some level of overfitting, the improvement in the testing R-squared after outlier removal is a positive sign. This suggests that removing outliers helped the model generalize slightly better, even if the primary issue of overfitting remains a consideration for further hyperparameter tuning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a923411"
      },
      "source": [
        "The Random Forest Regressor model, after outlier removal, shows a training R-squared of 0.9565 and a testing R-squared of 0.7011.\n",
        "\n",
        "Compared to its performance before outlier removal (Training R-squared: 0.9596, Testing R-squared: 0.6901):\n",
        "*   **Training R-squared** slightly decreased (from 0.9596 to 0.9565), indicating a minimal change in its fit to the training data. The model still fits the training data very well.\n",
        "*   **Testing R-squared** slightly increased (from 0.6901 to 0.7011), suggesting a minor improvement in its generalization to unseen data after outliers were removed.\n",
        "\n",
        "While the model still shows a notable difference between its training and testing R-squared, indicating some level of overfitting, the improvement in the testing R-squared after outlier removal is a positive sign. This suggests that removing outliers helped the model generalize slightly better, even if the primary issue of overfitting remains a consideration for further hyperparameter tuning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "561a2ffa"
      },
      "source": [
        "**Reasoning**:\n",
        "To retrain the Gradient Boosting Regressor model on the outlier-adjusted data, I will import the necessary class, instantiate the model, fit it to the cleaned training data, and then make predictions on both the cleaned training and testing sets.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0ea1d9d",
        "outputId": "55f0ab8a-4b96-49f9-ffbf-baa64d0dc6bd"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "# Instantiate Gradient Boosting Regressor model with the same random_state\n",
        "gbr_model_cleaned = GradientBoostingRegressor(random_state=42)\n",
        "\n",
        "# Fit the model to the cleaned training data\n",
        "gbr_model_cleaned.fit(X_train_cleaned, y_train_cleaned)\n",
        "\n",
        "# Make predictions on cleaned training and testing sets\n",
        "y_pred_train_gbr_cleaned = gbr_model_cleaned.predict(X_train_cleaned)\n",
        "y_pred_test_gbr_cleaned = gbr_model_cleaned.predict(X_test_cleaned)\n",
        "\n",
        "print(\"Gradient Boosting Regressor (Outlier-Adjusted) model trained and predictions made.\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting Regressor (Outlier-Adjusted) model trained and predictions made.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e13ec3d4"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the Gradient Boosting Regressor model has been retrained on the outlier-adjusted data and predictions have been made, I will calculate and print the R-squared scores for both the cleaned training and testing sets to evaluate its performance, as instructed by the overarching task structure.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff03846f",
        "outputId": "20406b1b-04ef-49c5-89f0-426cdaee617e"
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Calculate R-squared for cleaned training set\n",
        "r2_train_gbr_cleaned = r2_score(y_train_cleaned, y_pred_train_gbr_cleaned)\n",
        "print(f\"Gradient Boosting Regressor (Outlier-Adjusted) Training R-squared: {r2_train_gbr_cleaned:.4f}\")\n",
        "\n",
        "# Calculate R-squared for cleaned testing set\n",
        "r2_test_gbr_cleaned = r2_score(y_test_cleaned, y_pred_test_gbr_cleaned)\n",
        "print(f\"Gradient Boosting Regressor (Outlier-Adjusted) Testing R-squared: {r2_test_gbr_cleaned:.4f}\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting Regressor (Outlier-Adjusted) Training R-squared: 0.7213\n",
            "Gradient Boosting Regressor (Outlier-Adjusted) Testing R-squared: 0.6634\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4cfa341"
      },
      "source": [
        "The Gradient Boosting Regressor model, after outlier removal, shows a training R-squared of 0.7213 and a testing R-squared of 0.6634.\n",
        "\n",
        "Compared to its performance before outlier removal (Training R-squared: 0.7349, Testing R-squared: 0.6662):\n",
        "*   **Training R-squared** slightly decreased (from 0.7349 to 0.7213).\n",
        "*   **Testing R-squared** slightly decreased (from 0.6662 to 0.6634).\n",
        "\n",
        "The difference between training and testing R-squared remains small, indicating good generalization and less overfitting than the Random Forest model. However, unlike the Random Forest, outlier removal did not lead to an improvement in the testing R-squared for the Gradient Boosting Regressor; it remained largely similar or slightly worsened."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "365a9e16"
      },
      "source": [
        "## Compare Models and Select the Best (Outlier-Adjusted)\n",
        "\n",
        "### Subtask:\n",
        "Compare the R-squared scores of all three re-trained models on both training and testing sets. Select the best performing model based on its generalization capabilities (testing R-squared score) while aiming for reduced overfitting.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fbdc632"
      },
      "source": [
        "### Model Comparison and Selection (Outlier-Adjusted Data)\n",
        "\n",
        "Let's summarize the R-squared scores for all models after outlier removal:\n",
        "\n",
        "*   **Linear Regression (Outlier-Adjusted)**\n",
        "    *   Training R-squared: 0.1110\n",
        "    *   Testing R-squared: 0.0995\n",
        "    *   *Analysis*: Still very low R-squared, indicating severe underfitting. Performance slightly worsened after outlier removal compared to the original model, suggesting that linear models might not capture the underlying patterns effectively, or the removed data points were crucial for its (albeit poor) fit.\n",
        "\n",
        "*   **Random Forest Regressor (Outlier-Adjusted)**\n",
        "    *   Training R-squared: 0.9565\n",
        "    *   Testing R-squared: 0.7011\n",
        "    *   *Analysis*: Maintained a high training R-squared, with a slight improvement in testing R-squared (from 0.6901 to 0.7011) compared to the model before outlier removal. The large difference between training and testing still suggests overfitting, but the generalization to unseen data improved.\n",
        "\n",
        "*   **Gradient Boosting Regressor (Outlier-Adjusted)**\n",
        "    *   Training R-squared: 0.7213\n",
        "    *   Testing R-squared: 0.6634\n",
        "    *   *Analysis*: Training and testing R-squared scores are slightly lower than their pre-outlier removal counterparts (Training: 0.7349, Testing: 0.6662). This model shows less overfitting than the Random Forest, but its testing performance is slightly less than the outlier-adjusted Random Forest.\n",
        "\n",
        "**Conclusion:**\n",
        "\n",
        "Comparing the testing R-squared scores:\n",
        "*   Linear Regression: 0.0995\n",
        "*   Random Forest Regressor: 0.7011\n",
        "*   Gradient Boosting Regressor: 0.6634\n",
        "\n",
        "Based on the highest testing R-squared score, the **Random Forest Regressor (Outlier-Adjusted)** model is still the best performing model with a testing R-squared of **0.7011**. Although it still exhibits a noticeable gap between its training and testing scores, indicating some overfitting, its ability to generalize to unseen data (as measured by the testing R-squared) improved slightly after outlier removal. The Gradient Boosting Regressor, while showing less overfitting, did not achieve a higher testing R-squared in this specific instance. Therefore, for maximal predictive performance on unseen data, the Random Forest Regressor on the outlier-adjusted dataset is selected."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec667743"
      },
      "source": [
        "## Deploy Best Model with Gradio (Outlier-Adjusted)\n",
        "\n",
        "### Subtask:\n",
        "Create or update the Gradio web interface to deploy the newly selected best model, allowing users to input new data and get predictions. Ensure the deployment accounts for the outlier handling and feature scaling used in the best model's training pipeline.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f46e1da0"
      },
      "source": [
        "**Reasoning**:\n",
        "I will update the Gradio deployment to use the best performing model after outlier adjustment, which is the Random Forest Regressor (`rf_model_cleaned`). I will define a new prediction function, `predict_clv_cleaned`, that incorporates the necessary preprocessing steps (one-hot encoding, reindexing to match `X`'s original columns, and scaling with the global `scaler`) and then creates the Gradio interface with appropriate inputs and outputs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "1ba5253d",
        "outputId": "4b799b9a-f6fb-47b2-c431-a2e3df53a16b"
      },
      "source": [
        "import gradio as gr\n",
        "import pandas as pd\n",
        "\n",
        "# Best performing model is Random Forest Regressor (rf_model_cleaned) based on testing R-squared after outlier removal\n",
        "# (r2_test_rf_cleaned: 0.7011)\n",
        "\n",
        "# Get unique values for dropdowns from the 'df' (which is the one after dropping irrelevant columns but before one-hot encoding)\n",
        "# This 'categorical_unique_values' is already available from previous steps.\n",
        "\n",
        "def predict_clv_cleaned(*args):\n",
        "    # The order of args must match the order of feature names defined for the Gradio interface\n",
        "    # numerical_features: 'Income', 'Monthly Premium Auto', 'Months Since Last Claim', 'Months Since Policy Inception', 'Number of Open Complaints', 'Number of Policies', 'Total Claim Amount'\n",
        "    # categorical_features: 'State', 'Response', 'Coverage', 'Education', 'EmploymentStatus', 'Gender', 'Location Code', 'Marital Status', 'Policy Type', 'Policy', 'Renew Offer Type', 'Sales Channel', 'Vehicle Class', 'Vehicle Size'\n",
        "\n",
        "    input_data = {}\n",
        "    arg_idx = 0\n",
        "    # Populate numerical features\n",
        "    for feature in numerical_features:\n",
        "        input_data[feature] = [args[arg_idx]]\n",
        "        arg_idx += 1\n",
        "    # Populate categorical features\n",
        "    for feature in categorical_features:\n",
        "        input_data[feature] = [args[arg_idx]]\n",
        "        arg_idx += 1\n",
        "\n",
        "    input_df = pd.DataFrame(input_data)\n",
        "\n",
        "    # Apply one-hot encoding to categorical features\n",
        "    input_categorical_encoded = pd.get_dummies(input_df[categorical_features], drop_first=True)\n",
        "\n",
        "    # Prepare the input_df for scaling and prediction\n",
        "    # Drop original categorical columns from the input_df\n",
        "    input_df_processed = input_df.drop(columns=categorical_features)\n",
        "    # Concatenate with encoded features\n",
        "    input_df_processed = pd.concat([input_df_processed, input_categorical_encoded], axis=1)\n",
        "\n",
        "    # Reindex to ensure all columns from training (X.columns, from the original preprocessed X) are present and in the correct order\n",
        "    # Fill missing columns (for categories not present in the single input row) with 0\n",
        "    # This ensures consistency with the feature set X that rf_model_cleaned was trained on.\n",
        "    input_df_processed = input_df_processed.reindex(columns=X.columns, fill_value=0)\n",
        "\n",
        "    # Scale numerical features using the pre-fitted scaler\n",
        "    input_df_processed[numerical_features] = scaler.transform(input_df_processed[numerical_features])\n",
        "\n",
        "    # Make prediction using the best model (rf_model_cleaned)\n",
        "    prediction = rf_model_cleaned.predict(input_df_processed)[0] # [0] to get the single scalar value\n",
        "\n",
        "    return f\"Predicted Customer Lifetime Value: ${prediction:.2f}\"\n",
        "\n",
        "# Create Gradio interface inputs (using existing categorical_unique_values and numerical_features)\n",
        "inputs = []\n",
        "for feature in numerical_features:\n",
        "    inputs.append(gr.Number(label=feature))\n",
        "\n",
        "for feature in categorical_features:\n",
        "    inputs.append(gr.Dropdown(choices=categorical_unique_values[feature], label=feature))\n",
        "\n",
        "output = gr.Textbox(label=\"Predicted Customer Lifetime Value\")\n",
        "\n",
        "# Launch the Gradio interface\n",
        "gr.Interface(\n",
        "    fn=predict_clv_cleaned,\n",
        "    inputs=inputs,\n",
        "    outputs=output,\n",
        "    title=\"Customer Lifetime Value Prediction (Outlier-Adjusted)\",\n",
        "    description=\"Enter customer details to predict their Customer Lifetime Value using the outlier-adjusted model.\"\n",
        ").launch()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://168308559fe6f0d2ea.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://168308559fe6f0d2ea.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc419dd8"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Summarize the entire process, including the data preprocessing steps, the performance of each model, the rationale for selecting the best model, and a demonstration of the deployed Gradio interface for predicting Customer Lifetime Value.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7dee792"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "**What was the impact of outlier removal on model performance?**\n",
        "Outlier removal had a mixed impact on model performance. For the Linear Regression model, both training and testing R-squared scores decreased (from 0.1714 to 0.1110 for training and 0.1551 to 0.0995 for testing), indicating a worsening of its already poor fit. For the Random Forest Regressor, the testing R-squared slightly improved from 0.6901 to 0.7011, while the training R-squared slightly decreased from 0.9596 to 0.9565, suggesting a marginal improvement in generalization despite a slight increase in overfitting. The Gradient Boosting Regressor saw a slight decrease in both training (from 0.7349 to 0.7213) and testing (from 0.6662 to 0.6634) R-squared scores, meaning outlier removal did not benefit this model.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   **Outlier Removal Impact**: A total of 2698 rows, approximately 29.5% of the original dataset (9134 rows), were identified as outliers using the Interquartile Range (IQR) method and subsequently removed, resulting in a cleaned dataset of 6436 rows.\n",
        "*   **Linear Regression Performance**: After outlier removal, the Linear Regression model continued to exhibit severe underfitting, with a training R-squared of 0.1110 and a testing R-squared of 0.0995. This was a decrease from its pre-outlier removal performance (training R-squared: 0.1714, testing R-squared: 0.1551).\n",
        "*   **Random Forest Regressor Performance**: The Random Forest Regressor demonstrated the highest predictive power after outlier removal, achieving a training R-squared of 0.9565 and a testing R-squared of 0.7011. Its testing R-squared improved slightly from 0.6901 before outlier removal, suggesting better generalization.\n",
        "*   **Gradient Boosting Regressor Performance**: The Gradient Boosting Regressor showed robust performance with less overfitting than Random Forest, yielding a training R-squared of 0.7213 and a testing R-squared of 0.6634. However, these scores were marginally lower than its performance before outlier removal (training R-squared: 0.7349, testing R-squared: 0.6662).\n",
        "*   **Best Model Selection**: The Random Forest Regressor (Outlier-Adjusted) was selected as the best performing model due to its highest testing R-squared score of 0.7011, indicating the best generalization capability on unseen data among the evaluated models.\n",
        "*   **Gradio Deployment**: The selected Random Forest Regressor model was successfully deployed via a Gradio web interface, allowing users to input customer details and receive predictions for Customer Lifetime Value, with all necessary preprocessing steps handled internally.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   Further hyperparameter tuning for the Random Forest Regressor could potentially reduce the gap between training and testing R-squared, mitigating overfitting while maintaining or improving generalization performance.\n",
        "*   Given the significant portion of data removed due to outliers (29.5%), alternative outlier handling strategies, such as capping (winsorization) instead of removal, could be explored to retain more data and potentially improve model robustness for models that were negatively affected by complete removal.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e43f032"
      },
      "source": [
        "# Task\n",
        "## Log Transform Target Variable\n",
        "\n",
        "### Subtask:\n",
        "Apply a log transformation to the 'Customer Lifetime Value' (`y_cleaned`) to handle its skewed distribution. Create `y_log_transformed`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "844b3b62"
      },
      "source": [
        "## Log Transform Target Variable\n",
        "\n",
        "### Subtask:\n",
        "Apply a log transformation to the 'Customer Lifetime Value' (`y_cleaned`) to handle its skewed distribution. Create `y_log_transformed`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bd44c36"
      },
      "source": [
        "**Reasoning**:\n",
        "To apply a log transformation to the 'Customer Lifetime Value' (`y_cleaned`) and store it in `y_log_transformed`, I will import the `numpy` library and then use `np.log1p()` on `y_cleaned`. Finally, I will print the first 5 rows of the transformed series to verify the transformation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08486d62",
        "outputId": "aa519e70-2798-477e-d576-6f9547a6b0cc"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Apply log transformation to y_cleaned\n",
        "y_log_transformed = np.log1p(y_cleaned)\n",
        "\n",
        "# Print the first 5 rows of y_log_transformed to verify the transformation\n",
        "print(\"First 5 rows of y_log_transformed:\")\n",
        "print(y_log_transformed.head())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows of y_log_transformed:\n",
            "0    7.924622\n",
            "2    9.464085\n",
            "3    8.942051\n",
            "4    7.942608\n",
            "5    9.018853\n",
            "Name: Customer Lifetime Value, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "986584a9"
      },
      "source": [
        "## Re-split Data into Training and Testing Sets (Log-Transformed)\n",
        "\n",
        "### Subtask:\n",
        "Divide the outlier-adjusted features (`X_cleaned`) and the log-transformed target variable (`y_log_transformed`) into new training and testing sets to prepare for re-training the models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0eb8634"
      },
      "source": [
        "**Reasoning**:\n",
        "To divide the outlier-adjusted features and log-transformed target variable into training and testing sets, I will use `train_test_split` with the specified parameters and then print the shapes of the resulting datasets to confirm the split.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bee8ed6",
        "outputId": "92b330f5-1aab-4ae4-bf7b-67be1c8708a5"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the cleaned data with log-transformed target into training and testing sets\n",
        "X_train_log, X_test_log, y_train_log, y_test_log = train_test_split(X_cleaned, y_log_transformed, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Shape of X_train_log:\", X_train_log.shape)\n",
        "print(\"Shape of X_test_log:\", X_test_log.shape)\n",
        "print(\"Shape of y_train_log:\", y_train_log.shape)\n",
        "print(\"Shape of y_test_log:\", y_test_log.shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train_log: (5148, 50)\n",
            "Shape of X_test_log: (1288, 50)\n",
            "Shape of y_train_log: (5148,)\n",
            "Shape of y_test_log: (1288,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd7ab904"
      },
      "source": [
        "## Retrain and Evaluate Linear Regression Model (Log-Transformed)\n",
        "\n",
        "### Subtask:\n",
        "Retrain the Linear Regression model on the log-transformed training data and evaluate its performance using R-squared scores for both training and testing sets. Predictions will be inverse-transformed for evaluation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a65e63f"
      },
      "source": [
        "**Reasoning**:\n",
        "To retrain and evaluate the Linear Regression model on the log-transformed data as instructed, I will first import the necessary libraries, instantiate the model, fit it to the log-transformed training data, make predictions, inverse transform these predictions, and then calculate and print the R-squared scores for both training and testing sets using the original scale of the target variable.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5a9ca13",
        "outputId": "398a3843-5980-444a-f4ed-53897edd913e"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Instantiate Linear Regression model\n",
        "linear_model_log = LinearRegression()\n",
        "\n",
        "# Fit the model to the log-transformed training data\n",
        "linear_model_log.fit(X_train_log, y_train_log)\n",
        "\n",
        "# Make predictions on log-transformed training and testing sets\n",
        "y_pred_train_linear_log = linear_model_log.predict(X_train_log)\n",
        "y_pred_test_linear_log = linear_model_log.predict(X_test_log)\n",
        "\n",
        "# Inverse transform the predictions back to the original scale\n",
        "y_pred_train_linear_orig = np.expm1(y_pred_train_linear_log)\n",
        "y_pred_test_linear_orig = np.expm1(y_pred_test_linear_log)\n",
        "\n",
        "# Calculate R-squared for training set (comparing with original cleaned target)\n",
        "r2_train_linear_log_transformed = r2_score(y_train_cleaned.loc[y_train_log.index], y_pred_train_linear_orig)\n",
        "print(f\"Linear Regression (Log-Transformed) Training R-squared: {r2_train_linear_log_transformed:.4f}\")\n",
        "\n",
        "# Calculate R-squared for testing set (comparing with original cleaned target)\n",
        "r2_test_linear_log_transformed = r2_score(y_test_cleaned.loc[y_test_log.index], y_pred_test_linear_orig)\n",
        "print(f\"Linear Regression (Log-Transformed) Testing R-squared: {r2_test_linear_log_transformed:.4f}\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression (Log-Transformed) Training R-squared: 0.0408\n",
            "Linear Regression (Log-Transformed) Testing R-squared: 0.0248\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd61db13"
      },
      "source": [
        "The Linear Regression model, after log transformation and outlier removal, shows a training R-squared of 0.0408 and a testing R-squared of 0.0248. These scores are extremely low, indicating that the model performs very poorly. Comparing these to the previous Linear Regression models (before outlier removal: Training R-squared: 0.1714, Testing R-squared: 0.1551; after outlier removal: Training R-squared: 0.1110, Testing R-squared: 0.0995), the log transformation appears to have further degraded the Linear Regression model's performance. This suggests severe underfitting, as the model is unable to capture any meaningful patterns in the data even after these transformations. The very small difference between training and testing R-squared indicates no overfitting, but rather a consistent lack of fit across both sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bec27807"
      },
      "source": [
        "**Reasoning**:\n",
        "Now, following the pattern of the previous subtasks, I will retrain the Random Forest Regressor model on the log-transformed data, instantiate the model, fit it to the `X_train_log` and `y_train_log` data, and then make predictions on both the training and testing sets.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86c3735c",
        "outputId": "06f92712-8593-45cc-8281-f2cd06e38aad"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Instantiate Random Forest Regressor model with the same random_state\n",
        "rf_model_log = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# Fit the model to the log-transformed training data\n",
        "rf_model_log.fit(X_train_log, y_train_log)\n",
        "\n",
        "# Make predictions on log-transformed training and testing sets\n",
        "y_pred_train_rf_log = rf_model_log.predict(X_train_log)\n",
        "y_pred_test_rf_log = rf_model_log.predict(X_test_log)\n",
        "\n",
        "print(\"Random Forest Regressor (Log-Transformed) model trained and predictions made.\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Regressor (Log-Transformed) model trained and predictions made.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbf58970"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the Random Forest Regressor model has been retrained on the log-transformed data and predictions have been made, I will calculate and print the R-squared scores for both the training and testing sets, remembering to inverse transform the predictions to compare against the original scaled target variable.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98bd113e",
        "outputId": "a8a7494e-774b-4799-db7c-e314e9d77751"
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Inverse transform the predictions back to the original scale\n",
        "y_pred_train_rf_orig = np.expm1(y_pred_train_rf_log)\n",
        "y_pred_test_rf_orig = np.expm1(y_pred_test_rf_log)\n",
        "\n",
        "# Calculate R-squared for training set (comparing with original cleaned target)\n",
        "r2_train_rf_log_transformed = r2_score(y_train_cleaned.loc[y_train_log.index], y_pred_train_rf_orig)\n",
        "print(f\"Random Forest Regressor (Log-Transformed) Training R-squared: {r2_train_rf_log_transformed:.4f}\")\n",
        "\n",
        "# Calculate R-squared for testing set (comparing with original cleaned target)\n",
        "r2_test_rf_log_transformed = r2_score(y_test_cleaned.loc[y_test_log.index], y_pred_test_rf_orig)\n",
        "print(f\"Random Forest Regressor (Log-Transformed) Testing R-squared: {r2_test_rf_log_transformed:.4f}\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Regressor (Log-Transformed) Training R-squared: 0.9426\n",
            "Random Forest Regressor (Log-Transformed) Testing R-squared: 0.6947\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfb10cda"
      },
      "source": [
        "The Random Forest Regressor model, after log transformation and outlier removal, shows a training R-squared of 0.9426 and a testing R-squared of 0.6947.\n",
        "\n",
        "Compared to its performance before log transformation (but after outlier removal) (Training R-squared: 0.9565, Testing R-squared: 0.7011):\n",
        "*   **Training R-squared** slightly decreased (from 0.9565 to 0.9426).\n",
        "*   **Testing R-squared** also slightly decreased (from 0.7011 to 0.6947).\n",
        "\n",
        "While the model still shows a high training R-squared and a notable difference between its training and testing R-squared, indicating some level of overfitting, the log transformation did not improve the testing R-squared. In this case, removing outliers improved the RFR model slightly, but applying a log transformation to the target variable did not lead to further improvements in its generalization capability as measured by the testing R-squared."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d45a6325"
      },
      "source": [
        "**Reasoning**:\n",
        "Now, I will retrain the Gradient Boosting Regressor model on the log-transformed data, instantiate the model, fit it to the `X_train_log` and `y_train_log` data, and then make predictions on both the training and testing sets.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bd43e5f",
        "outputId": "ad52fb40-47cc-4c00-a0b7-a04081d3b9ab"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "# Instantiate Gradient Boosting Regressor model with the same random_state\n",
        "gbr_model_log = GradientBoostingRegressor(random_state=42)\n",
        "\n",
        "# Fit the model to the log-transformed training data\n",
        "gbr_model_log.fit(X_train_log, y_train_log)\n",
        "\n",
        "# Make predictions on log-transformed training and testing sets\n",
        "y_pred_train_gbr_log = gbr_model_log.predict(X_train_log)\n",
        "y_pred_test_gbr_log = gbr_model_log.predict(X_test_log)\n",
        "\n",
        "print(\"Gradient Boosting Regressor (Log-Transformed) model trained and predictions made.\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting Regressor (Log-Transformed) model trained and predictions made.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2c70e3a"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the Gradient Boosting Regressor model has been retrained on the log-transformed data and predictions have been made, I will calculate and print the R-squared scores for both the training and testing sets, remembering to inverse transform the predictions to compare against the original scaled target variable.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e3f28f3",
        "outputId": "f1d507b6-5550-4014-fe84-fbf5ab74cba1"
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Inverse transform the predictions back to the original scale\n",
        "y_pred_train_gbr_orig = np.expm1(y_pred_train_gbr_log)\n",
        "y_pred_test_gbr_orig = np.expm1(y_pred_test_gbr_log)\n",
        "\n",
        "# Calculate R-squared for training set (comparing with original cleaned target)\n",
        "r2_train_gbr_log_transformed = r2_score(y_train_cleaned.loc[y_train_log.index], y_pred_train_gbr_orig)\n",
        "print(f\"Gradient Boosting Regressor (Log-Transformed) Training R-squared: {r2_train_gbr_log_transformed:.4f}\")\n",
        "\n",
        "# Calculate R-squared for testing set (comparing with original cleaned target)\n",
        "r2_test_gbr_log_transformed = r2_score(y_test_cleaned.loc[y_test_log.index], y_pred_test_gbr_orig)\n",
        "print(f\"Gradient Boosting Regressor (Log-Transformed) Testing R-squared: {r2_test_gbr_log_transformed:.4f}\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting Regressor (Log-Transformed) Training R-squared: 0.6963\n",
            "Gradient Boosting Regressor (Log-Transformed) Testing R-squared: 0.6523\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "645841d6"
      },
      "source": [
        "The Gradient Boosting Regressor model, after log transformation and outlier removal, shows a training R-squared of 0.6963 and a testing R-squared of 0.6523.\n",
        "\n",
        "Compared to its performance before log transformation (but after outlier removal) (Training R-squared: 0.7213, Testing R-squared: 0.6634):\n",
        "*   **Training R-squared** decreased (from 0.7213 to 0.6963).\n",
        "*   **Testing R-squared** also decreased (from 0.6634 to 0.6523).\n",
        "\n",
        "The log transformation had a slightly negative impact on the Gradient Boosting Regressor's performance, resulting in marginally lower R-squared scores for both training and testing sets. While the difference between training and testing R-squared remains relatively small, suggesting good generalization and less overfitting compared to the Random Forest model, the log transformation did not yield an improvement for this model in this scenario."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0a826d0"
      },
      "source": [
        "## Compare Models and Select the Best (Log-Transformed and Outlier-Adjusted)\n",
        "\n",
        "### Subtask:\n",
        "Compare the R-squared scores of all three re-trained models on both training and testing sets. Select the best performing model based on its generalization capabilities (testing R-squared score) while aiming for reduced overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b748091"
      },
      "source": [
        "### Model Comparison and Selection (Log-Transformed and Outlier-Adjusted Data)\n",
        "\n",
        "Let's summarize the R-squared scores for all models after log transformation and outlier removal:\n",
        "\n",
        "*   **Linear Regression (Log-Transformed and Outlier-Adjusted)**\n",
        "    *   Training R-squared: 0.0408\n",
        "    *   Testing R-squared: 0.0248\n",
        "    *   *Analysis*: Performance significantly worsened compared to previous iterations, indicating severe underfitting. The log transformation, in combination with outlier removal, proved detrimental for this model, suggesting it's unsuitable for this dataset and transformations.\n",
        "\n",
        "*   **Random Forest Regressor (Log-Transformed and Outlier-Adjusted)**\n",
        "    *   Training R-squared: 0.9426\n",
        "    *   Testing R-squared: 0.6947\n",
        "    *   *Analysis*: Maintains a high training R-squared, but the testing R-squared (0.6947) is slightly lower than the Random Forest model with only outlier removal (0.7011). This suggests that log transformation did not further improve its generalization and might have slightly hindered it. Overfitting is still a concern due to the large gap between training and testing scores.\n",
        "\n",
        "*   **Gradient Boosting Regressor (Log-Transformed and Outlier-Adjusted)**\n",
        "    *   Training R-squared: 0.6963\n",
        "    *   Testing R-squared: 0.6523\n",
        "    *   *Analysis*: Both training and testing R-squared scores decreased compared to the Gradient Boosting model with only outlier removal (Training: 0.7213, Testing: 0.6634). The log transformation had a slightly negative impact. It still shows less overfitting than Random Forest, but its predictive power on the test set is now lower than the Random Forest model.\n",
        "\n",
        "**Overall Conclusion After Outlier Removal and Log Transformation:**\n",
        "\n",
        "Comparing the testing R-squared scores:\n",
        "*   Linear Regression: 0.0248\n",
        "*   Random Forest Regressor: 0.6947\n",
        "*   Gradient Boosting Regressor: 0.6523\n",
        "\n",
        "The **Random Forest Regressor (Outlier-Adjusted)** without log transformation remains the best performing model so far, achieving a testing R-squared of **0.7011**. The Random Forest Regressor (Log-Transformed and Outlier-Adjusted) is a close second with 0.6947. Given that the log transformation slightly decreased the performance of both Random Forest and Gradient Boosting models, and severely worsened Linear Regression, it seems that for this dataset, the log transformation did not provide the expected benefits. Therefore, the **Random Forest Regressor (Outlier-Adjusted)** model (from the previous subtask) is still considered the best model for deployment, as it demonstrated the highest testing R-squared."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3a3fcc1"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "**What was the impact of outlier removal on model performance?**\n",
        "Outlier removal had a mixed impact on model performance. For the Linear Regression model, both training and testing R-squared scores decreased (from 0.1714 to 0.1110 for training and 0.1551 to 0.0995 for testing), indicating a worsening of its already poor fit. For the Random Forest Regressor, the testing R-squared slightly improved from 0.6901 to 0.7011, while the training R-squared slightly decreased from 0.9596 to 0.9565, suggesting a marginal improvement in generalization despite a slight increase in overfitting. The Gradient Boosting Regressor saw a slight decrease in both training (from 0.7349 to 0.7213) and testing (from 0.6662 to 0.6634) R-squared scores, meaning outlier removal did not benefit this model.\n",
        "\n",
        "**What was the impact of log transformation on model performance?**\n",
        "Applying a log transformation to the target variable after outlier removal generally did not improve model performance for this dataset. For the Linear Regression model, log transformation further degraded performance (testing R-squared dropped from 0.0995 to 0.0248), indicating severe underfitting. For the Random Forest Regressor, log transformation resulted in a slight decrease in testing R-squared (from 0.7011 to 0.6947). Similarly, for the Gradient Boosting Regressor, testing R-squared slightly decreased (from 0.6634 to 0.6523). This suggests that for these models and this dataset, the raw or simply outlier-adjusted target variable was more suitable than its log-transformed version, as log transformation did not lead to improved predictive power or reduced overfitting in this case.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   **Outlier Removal Impact**: A total of 2698 rows, approximately 29.5% of the original dataset (9134 rows), were identified as outliers using the Interquartile Range (IQR) method and subsequently removed, resulting in a cleaned dataset of 6436 rows.\n",
        "*   **Linear Regression Performance**:\n",
        "    *   Before outlier/log transform: Training R-squared: 0.1714, Testing R-squared: 0.1551.\n",
        "    *   After outlier removal: Training R-squared: 0.1110, Testing R-squared: 0.0995.\n",
        "    *   After outlier and log transform: Training R-squared: 0.0408, Testing R-squared: 0.0248. The model consistently suffered from severe underfitting, with performance degrading further after transformations.\n",
        "*   **Random Forest Regressor Performance**:\n",
        "    *   Before outlier/log transform: Training R-squared: 0.9596, Testing R-squared: 0.6901.\n",
        "    *   After outlier removal: Training R-squared: 0.9565, Testing R-squared: 0.7011. This was the best performance overall.\n",
        "    *   After outlier and log transform: Training R-squared: 0.9426, Testing R-squared: 0.6947. Performance slightly declined after log transformation. The model consistently showed signs of overfitting (large gap between training and testing R-squared).\n",
        "*   **Gradient Boosting Regressor Performance**:\n",
        "    *   Before outlier/log transform: Training R-squared: 0.7349, Testing R-squared: 0.6662.\n",
        "    *   After outlier removal: Training R-squared: 0.7213, Testing R-squared: 0.6634.\n",
        "    *   After outlier and log transform: Training R-squared: 0.6963, Testing R-squared: 0.6523. Performance slightly declined after both transformations. This model generally showed less overfitting than Random Forest.\n",
        "*   **Best Model Selection**: The **Random Forest Regressor (Outlier-Adjusted)**, trained on data with outliers removed but *without* log transformation, was selected as the best performing model due to its highest testing R-squared score of **0.7011**. This model demonstrated the best generalization capability on unseen data among all evaluated scenarios.\n",
        "*   **Gradio Deployment**: The selected Random Forest Regressor model (trained on outlier-adjusted data) was successfully deployed via a Gradio web interface, allowing users to input customer details and receive predictions for Customer Lifetime Value, with all necessary preprocessing steps handled internally.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   **Overfitting Mitigation**: While the Random Forest Regressor had the best testing performance, the notable difference between its training and testing R-squared scores indicates overfitting. Further hyperparameter tuning (e.g., using GridSearchCV or RandomizedSearchCV) or techniques like pruning could be explored to improve its generalization capabilities and potentially reduce this gap without sacrificing too much predictive power.\n",
        "*   **Alternative Outlier Handling**: Given the significant portion of data removed due to outliers (29.5%), alternative outlier handling strategies, such as capping (winsorization) instead of complete removal, could be explored to retain more data. This might be especially beneficial for models that saw a performance decrease after outlier removal (like Linear Regression and Gradient Boosting).\n",
        "*   **Advanced Feature Engineering**: Given the overall R-squared values, exploring more advanced feature engineering, such as interaction terms, polynomial features, or different ways to encode categorical variables, could enhance the models' ability to capture more complex relationships and further improve predictive accuracy.\n",
        "*   **Different Model Architectures**: Experimenting with other regression models or ensemble techniques could potentially yield better results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18d24ac4"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "**What was the impact of outlier removal on model performance?**\n",
        "Outlier removal had a mixed impact on model performance. For the Linear Regression model, both training and testing R-squared scores decreased (from 0.1714 to 0.1110 for training and 0.1551 to 0.0995 for testing), indicating a worsening of its already poor fit. For the Random Forest Regressor, the testing R-squared slightly improved from 0.6901 to 0.7011, while the training R-squared slightly decreased from 0.9596 to 0.9565, suggesting a marginal improvement in generalization despite a slight increase in overfitting. The Gradient Boosting Regressor saw a slight decrease in both training (from 0.7349 to 0.7213) and testing (from 0.6662 to 0.6634) R-squared scores, meaning outlier removal did not benefit this model.\n",
        "\n",
        "**What was the impact of log transformation on model performance?**\n",
        "Applying a log transformation to the target variable after outlier removal generally did not improve model performance for this dataset. For the Linear Regression model, log transformation further degraded performance (testing R-squared dropped from 0.0995 to 0.0248), indicating severe underfitting. For the Random Forest Regressor, log transformation resulted in a slight decrease in testing R-squared (from 0.7011 to 0.6947). Similarly, for the Gradient Boosting Regressor, testing R-squared slightly decreased (from 0.6634 to 0.6523). This suggests that for these models and this dataset, the raw or simply outlier-adjusted target variable was more suitable than its log-transformed version, as log transformation did not lead to improved predictive power or reduced overfitting in this case.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   **Outlier Removal Impact**: A total of 2698 rows, approximately 29.5% of the original dataset (9134 rows), were identified as outliers using the Interquartile Range (IQR) method and subsequently removed, resulting in a cleaned dataset of 6436 rows.\n",
        "*   **Linear Regression Performance**:\n",
        "    *   Before outlier/log transform: Training R-squared: 0.1714, Testing R-squared: 0.1551.\n",
        "    *   After outlier removal: Training R-squared: 0.1110, Testing R-squared: 0.0995.\n",
        "    *   After outlier and log transform: Training R-squared: 0.0408, Testing R-squared: 0.0248. The model consistently suffered from severe underfitting, with performance degrading further after transformations.\n",
        "*   **Random Forest Regressor Performance**:\n",
        "    *   Before outlier/log transform: Training R-squared: 0.9596, Testing R-squared: 0.6901.\n",
        "    *   After outlier removal: Training R-squared: 0.9565, Testing R-squared: 0.7011. This was the best performance overall.\n",
        "    *   After outlier and log transform: Training R-squared: 0.9426, Testing R-squared: 0.6947. Performance slightly declined after log transformation. The model consistently showed signs of overfitting (large gap between training and testing R-squared).\n",
        "*   **Gradient Boosting Regressor Performance**:\n",
        "    *   Before outlier/log transform: Training R-squared: 0.7349, Testing R-squared: 0.6662.\n",
        "    *   After outlier removal: Training R-squared: 0.7213, Testing R-squared: 0.6634.\n",
        "    *   After outlier and log transform: Training R-squared: 0.6963, Testing R-squared: 0.6523. Performance slightly declined after both transformations. This model generally showed less overfitting than Random Forest.\n",
        "*   **Best Model Selection**: The **Random Forest Regressor (Outlier-Adjusted)**, trained on data with outliers removed but *without* log transformation, was selected as the best performing model due to its highest testing R-squared score of **0.7011**. This model demonstrated the best generalization capability on unseen data among all evaluated scenarios.\n",
        "*   **Gradio Deployment**: The selected Random Forest Regressor model (trained on outlier-adjusted data) was successfully deployed via a Gradio web interface, allowing users to input customer details and receive predictions for Customer Lifetime Value, with all necessary preprocessing steps handled internally.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   **Overfitting Mitigation**: While the Random Forest Regressor had the best testing performance, the notable difference between its training and testing R-squared scores indicates overfitting. Further hyperparameter tuning (e.g., using GridSearchCV or RandomizedSearchCV) or techniques like pruning could be explored to improve its generalization capabilities and potentially reduce this gap without sacrificing too much predictive power.\n",
        "*   **Alternative Outlier Handling**: Given the significant portion of data removed due to outliers (29.5%), alternative outlier handling strategies, such as capping (winsorization) instead of complete removal, could be explored to retain more data. This might be especially beneficial for models that saw a performance decrease after outlier removal (like Linear Regression and Gradient Boosting).\n",
        "*   **Advanced Feature Engineering**: Given the overall R-squared values, exploring more advanced feature engineering, such as interaction terms, polynomial features, or different ways to encode categorical variables, could enhance the models' ability to capture more complex relationships and further improve predictive accuracy.\n",
        "*   **Different Model Architectures**: Experimenting with other regression models or ensemble techniques could potentially yield better results.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6484fb27"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "**What was the impact of outlier removal on model performance?**\n",
        "Outlier removal had a mixed impact on model performance. For the Linear Regression model, both training and testing R-squared scores decreased (from 0.1714 to 0.1110 for training and 0.1551 to 0.0995 for testing), indicating a worsening of its already poor fit. For the Random Forest Regressor, the testing R-squared slightly improved from 0.6901 to 0.7011, while the training R-squared slightly decreased from 0.9596 to 0.9565, suggesting a marginal improvement in generalization despite a slight increase in overfitting. The Gradient Boosting Regressor saw a slight decrease in both training (from 0.7349 to 0.7213) and testing (from 0.6662 to 0.6634) R-squared scores, meaning outlier removal did not benefit this model.\n",
        "\n",
        "**What was the impact of log transformation on model performance?**\n",
        "Applying a log transformation to the target variable after outlier removal generally did not improve model performance for this dataset. For the Linear Regression model, log transformation further degraded performance (testing R-squared dropped from 0.0995 to 0.0248), indicating severe underfitting. For the Random Forest Regressor, log transformation resulted in a slight decrease in testing R-squared (from 0.7011 to 0.6947). Similarly, for the Gradient Boosting Regressor, testing R-squared slightly decreased (from 0.6634 to 0.6523). This suggests that for these models and this dataset, the raw or simply outlier-adjusted target variable was more suitable than its log-transformed version, as log transformation did not lead to improved predictive power or reduced overfitting in this case.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   **Outlier Removal Impact**: A total of 2698 rows, approximately 29.5% of the original dataset (9134 rows), were identified as outliers using the Interquartile Range (IQR) method and subsequently removed, resulting in a cleaned dataset of 6436 rows.\n",
        "*   **Linear Regression Performance**:\n",
        "    *   Before outlier/log transform: Training R-squared: 0.1714, Testing R-squared: 0.1551.\n",
        "    *   After outlier removal: Training R-squared: 0.1110, Testing R-squared: 0.0995.\n",
        "    *   After outlier and log transform: Training R-squared: 0.0408, Testing R-squared: 0.0248. The model consistently suffered from severe underfitting, with performance degrading further after transformations.\n",
        "*   **Random Forest Regressor Performance**:\n",
        "    *   Before outlier/log transform: Training R-squared: 0.9596, Testing R-squared: 0.6901.\n",
        "    *   After outlier removal: Training R-squared: 0.9565, Testing R-squared: 0.7011. This was the best performance overall.\n",
        "    *   After outlier and log transform: Training R-squared: 0.9426, Testing R-squared: 0.6947. Performance slightly declined after log transformation. The model consistently showed signs of overfitting (large gap between training and testing R-squared).\n",
        "*   **Gradient Boosting Regressor Performance**:\n",
        "    *   Before outlier/log transform: Training R-squared: 0.7349, Testing R-squared: 0.6662.\n",
        "    *   After outlier removal: Training R-squared: 0.7213, Testing R-squared: 0.6634.\n",
        "    *   After outlier and log transform: Training R-squared: 0.6963, Testing R-squared: 0.6523. Performance slightly declined after both transformations. This model generally showed less overfitting than Random Forest.\n",
        "*   **Best Model Selection**: The **Random Forest Regressor (Outlier-Adjusted)**, trained on data with outliers removed but *without* log transformation, was selected as the best performing model due to its highest testing R-squared score of **0.7011**. This model demonstrated the best generalization capability on unseen data among all evaluated scenarios.\n",
        "*   **Gradio Deployment**: The selected Random Forest Regressor model (trained on outlier-adjusted data) was successfully deployed via a Gradio web interface, allowing users to input customer details and receive predictions for Customer Lifetime Value, with all necessary preprocessing steps handled internally.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   **Overfitting Mitigation**: While the Random Forest Regressor had the best testing performance, the notable difference between its training and testing R-squared scores indicates overfitting. Further hyperparameter tuning (e.g., using GridSearchCV or RandomizedSearchCV) or techniques like pruning could be explored to improve its generalization capabilities and potentially reduce this gap without sacrificing too much predictive power.\n",
        "*   **Alternative Outlier Handling**: Given the significant portion of data removed due to outliers (29.5%), alternative outlier handling strategies, such as capping (winsorization) instead of complete removal, could be explored to retain more data. This might be especially beneficial for models that saw a performance decrease after outlier removal (like Linear Regression and Gradient Boosting).\n",
        "*   **Advanced Feature Engineering**: Given the overall R-squared values, exploring more advanced feature engineering, such as interaction terms, polynomial features, or different ways to encode categorical variables, could enhance the models' ability to capture more complex relationships and further improve predictive accuracy.\n",
        "*   **Different Model Architectures**: Experimenting with other regression models or ensemble techniques could potentially yield better results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a056c2f"
      },
      "source": [
        "## Compare Models and Select the Best (Log-Transformed)\n",
        "\n",
        "### Subtask:\n",
        "Compare the R-squared scores of all three re-trained models on both training and testing sets with log-transformed target. Select the best performing model based on its generalization capabilities (testing R-squared score) while aiming for reduced overfitting. Ensure that the R-squared is calculated on inverse-transformed predictions against the original y_test values.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c989717"
      },
      "source": [
        "### Model Comparison and Selection (Log-Transformed Target)\n",
        "\n",
        "Let's summarize the R-squared scores for all models after log transformation of the target variable and outlier removal:\n",
        "\n",
        "*   **Linear Regression (Log-Transformed)**\n",
        "    *   Training R-squared: 0.0408\n",
        "    *   Testing R-squared: 0.0248\n",
        "    *   *Analysis*: The performance of the Linear Regression model significantly degraded after log transformation, resulting in extremely low R-squared scores. This model continues to severely underfit the data.\n",
        "\n",
        "*   **Random Forest Regressor (Log-Transformed)**\n",
        "    *   Training R-squared: 0.9426\n",
        "    *   Testing R-squared: 0.6947\n",
        "    *   *Analysis*: This model maintains a high training R-squared, but the testing R-squared is slightly lower than its performance on the outlier-adjusted data without log transformation (0.7011). The gap between training and testing scores indicates continued overfitting, though its testing performance is still competitive.\n",
        "\n",
        "*   **Gradient Boosting Regressor (Log-Transformed)**\n",
        "    *   Training R-squared: 0.6963\n",
        "    *   Testing R-squared: 0.6523\n",
        "    *   *Analysis*: Both training and testing R-squared scores for this model are slightly lower compared to its performance on the outlier-adjusted data without log transformation (Training: 0.7213, Testing: 0.6634). It shows less overfitting than the Random Forest, but its testing performance is the lowest among the tree-based models after log transformation.\n",
        "\n",
        "**Conclusion:**\n",
        "\n",
        "Comparing the testing R-squared scores:\n",
        "*   Linear Regression: 0.0248\n",
        "*   Random Forest Regressor: 0.6947\n",
        "*   Gradient Boosting Regressor: 0.6523\n",
        "\n",
        "Based on the highest testing R-squared score, the **Random Forest Regressor (Log-Transformed)** model still performs the best with a testing R-squared of **0.6947**. Although the log transformation slightly decreased its testing R-squared compared to the outlier-adjusted model without log transformation (0.7011), it still outperforms the other models significantly. It exhibits some overfitting (difference between training and testing R-squared is 0.2479), but its predictive power on unseen data is superior. Therefore, the Random Forest Regressor trained on the outlier-adjusted data with a log-transformed target variable is selected as the best model for this iteration, considering its overall highest predictive performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3144eaae"
      },
      "source": [
        "## Deploy Best Model with Gradio (Log-Transformed)\n",
        "\n",
        "### Subtask:\n",
        "Create or update the Gradio web interface to deploy the newly selected best model, allowing users to input new data and get predictions. Ensure the deployment accounts for the log transformation and inverse log transformation for predictions, as well as prior preprocessing steps.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b54f865"
      },
      "source": [
        "**Reasoning**:\n",
        "I will define the `predict_clv_log_transformed` function to handle new data inputs, preprocess them (one-hot encode categorical features, reindex to match training columns, scale numerical features, and inverse transform the prediction), and then create and launch a Gradio interface with appropriate input and output components to deploy the best performing model (`rf_model_log`).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "c05a0300",
        "outputId": "e98c881c-395d-4795-aecc-bebd769340b8"
      },
      "source": [
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Best performing model is Random Forest Regressor (rf_model_log) based on testing R-squared after log transformation\n",
        "# (r2_test_rf_log_transformed: 0.6947)\n",
        "\n",
        "def predict_clv_log_transformed(*args):\n",
        "    # The order of args must match the order of feature names defined for the Gradio interface\n",
        "    # numerical_features: 'Income', 'Monthly Premium Auto', 'Months Since Last Claim', 'Months Since Policy Inception', 'Number of Open Complaints', 'Number of Policies', 'Total Claim Amount'\n",
        "    # categorical_features: 'State', 'Response', 'Coverage', 'Education', 'EmploymentStatus', 'Gender', 'Location Code', 'Marital Status', 'Policy Type', 'Policy', 'Renew Offer Type', 'Sales Channel', 'Vehicle Class', 'Vehicle Size'\n",
        "\n",
        "    input_data = {}\n",
        "    arg_idx = 0\n",
        "    # Populate numerical features\n",
        "    for feature in numerical_features:\n",
        "        input_data[feature] = [args[arg_idx]]\n",
        "        arg_idx += 1\n",
        "    # Populate categorical features\n",
        "    for feature in categorical_features:\n",
        "        input_data[feature] = [args[arg_idx]]\n",
        "        arg_idx += 1\n",
        "\n",
        "    input_df = pd.DataFrame(input_data)\n",
        "\n",
        "    # Apply one-hot encoding to categorical features\n",
        "    input_categorical_encoded = pd.get_dummies(input_df[categorical_features], drop_first=True)\n",
        "\n",
        "    # Prepare the input_df for scaling and prediction\n",
        "    # Drop original categorical columns from the input_df\n",
        "    input_df_processed = input_df.drop(columns=categorical_features)\n",
        "    # Concatenate with encoded features\n",
        "    input_df_processed = pd.concat([input_df_processed, input_categorical_encoded], axis=1)\n",
        "\n",
        "    # Reindex to ensure all columns from training (X.columns, from the original preprocessed X) are present and in the correct order\n",
        "    # Fill missing columns (for categories not present in the single input row) with 0\n",
        "    # X.columns represents the feature set after one-hot encoding before outlier removal and log transform, which is consistent with X_cleaned and X_train_log column structure.\n",
        "    input_df_processed = input_df_processed.reindex(columns=X.columns, fill_value=0)\n",
        "\n",
        "    # Scale numerical features using the pre-fitted scaler\n",
        "    input_df_processed[numerical_features] = scaler.transform(input_df_processed[numerical_features])\n",
        "\n",
        "    # Make prediction using the best model (rf_model_log)\n",
        "    predicted_log_clv = rf_model_log.predict(input_df_processed)[0]\n",
        "\n",
        "    # Inverse transform the prediction back to the original scale\n",
        "    prediction = np.expm1(predicted_log_clv)\n",
        "\n",
        "    return f\"Predicted Customer Lifetime Value: ${prediction:.2f}\"\n",
        "\n",
        "# Create Gradio interface inputs (using existing categorical_unique_values and numerical_features)\n",
        "inputs = []\n",
        "for feature in numerical_features:\n",
        "    inputs.append(gr.Number(label=feature))\n",
        "\n",
        "for feature in categorical_features:\n",
        "    inputs.append(gr.Dropdown(choices=categorical_unique_values[feature], label=feature))\n",
        "\n",
        "output = gr.Textbox(label=\"Predicted Customer Lifetime Value\")\n",
        "\n",
        "# Launch the Gradio interface\n",
        "gr.Interface(\n",
        "    fn=predict_clv_log_transformed,\n",
        "    inputs=inputs,\n",
        "    outputs=output,\n",
        "    title=\"Customer Lifetime Value Prediction (Outlier-Adjusted, Log-Transformed)\",\n",
        "    description=\"Enter customer details to predict their Customer Lifetime Value using the outlier-adjusted and log-transformed model.\"\n",
        ").launch()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://0dfd4fd360bd606027.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://0dfd4fd360bd606027.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0052bb1"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Summarize the entire process, focusing on the impact of log transformation on model performance, highlight the final best model, and demonstrate the updated Gradio interface.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51cfb7ca"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "**What was the impact of log transformation on model performance?**\n",
        "Applying a log transformation to the target variable (`Customer Lifetime Value`) after outlier removal generally did not improve model performance for this dataset.\n",
        "*   For the Linear Regression model, log transformation further degraded performance, with the testing R-squared dropping significantly from 0.0995 to 0.0248, indicating severe underfitting.\n",
        "*   For the Random Forest Regressor, log transformation resulted in a slight decrease in testing R-squared from 0.7011 to 0.6947.\n",
        "*   Similarly, for the Gradient Boosting Regressor, testing R-squared slightly decreased from 0.6634 to 0.6523.\n",
        "This suggests that for these models and this dataset, the raw or simply outlier-adjusted target variable was more suitable than its log-transformed version, as log transformation did not lead to improved predictive power or reduced overfitting.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   **Log Transformation Application**: The 'Customer Lifetime Value' (`y_cleaned`) was successfully log-transformed using `np.log1p()` to create `y_log_transformed` to address its skewed distribution.\n",
        "*   **Data Resplitting**: The outlier-adjusted features (`X_cleaned`) and the new log-transformed target (`y_log_transformed`) were re-split into training and testing sets, resulting in `X_train_log` (5148, 50), `X_test_log` (1288, 50), `y_train_log` (5148,), and `y_test_log` (1288,).\n",
        "*   **Linear Regression (Log-Transformed) Performance**: The Linear Regression model, after log transformation and outlier removal, showed extremely poor performance with a training R-squared of 0.0408 and a testing R-squared of 0.0248, indicating severe underfitting and a degradation from previous iterations.\n",
        "*   **Random Forest Regressor (Log-Transformed) Performance**: This model achieved a training R-squared of 0.9426 and a testing R-squared of 0.6947. While still the best among the log-transformed models, its testing R-squared slightly decreased from the Random Forest model with only outlier removal (0.7011).\n",
        "*   **Gradient Boosting Regressor (Log-Transformed) Performance**: This model yielded a training R-squared of 0.6963 and a testing R-squared of 0.6523. Similar to Random Forest, its performance slightly declined after log transformation compared to the outlier-adjusted model without it (testing R-squared of 0.6634).\n",
        "*   **Best Model Selection**: Despite a slight reduction in testing R-squared compared to the Random Forest model without log transformation (0.7011 vs. 0.6947), the **Random Forest Regressor trained on the outlier-adjusted data with a log-transformed target variable** was selected as the best model for this iteration, demonstrating the highest predictive performance (testing R-squared of 0.6947) among the log-transformed models.\n",
        "*   **Gradio Deployment**: The selected Random Forest Regressor model (`rf_model_log`) was successfully deployed via a Gradio web interface, which is accessible via a public URL `https://0dfd4fd360bd606027.gradio.live`. The interface properly handles all preprocessing steps (one-hot encoding, reindexing, numerical scaling) and performs inverse log transformation on predictions to present Customer Lifetime Value in its original scale.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   **Re-evaluate Log Transformation**: Given that log transformation did not universally improve model performance and even degraded some, further investigation into the optimal transformation for the target variable, or even refraining from transformation, should be considered for this dataset.\n",
        "*   **Hyperparameter Tuning for Overfitting**: The chosen Random Forest Regressor still exhibits a notable gap between its training (0.9426) and testing (0.6947) R-squared scores, indicating overfitting. Advanced hyperparameter tuning techniques (e.g., GridSearchCV, RandomizedSearchCV) could be employed to optimize model complexity and improve generalization.\n"
      ]
    }
  ]
}